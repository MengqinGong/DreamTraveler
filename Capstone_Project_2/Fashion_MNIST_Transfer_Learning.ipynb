{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB22eqT-V7H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1401a944-33c9-4536-e082-3011f0317c53"
      },
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import collections\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSXV-673WTWJ",
        "colab_type": "code",
        "outputId": "19a9fba3-cfff-41c8-b1ff-355328878fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load Fashion MNIST dataset from Keras\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape, \"y_test shape:\", y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28) y_test shape: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo2GqRhQWYUR",
        "colab_type": "code",
        "outputId": "dcac1d60-3110-4110-a3cb-3392ed3c669f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Feature scaling: divide features by 255 to get a range of 0 to 1\n",
        "x_train_scaled = x_train / 255.0\n",
        "x_test_scaled = x_test / 255.0\n",
        "\n",
        "# Convert y_train and y_test to one-hot vector\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# Flatten training and test data\n",
        "x_train_scaled_reshaped = np.reshape(x_train_scaled, \n",
        "                                     (x_train.shape[0], x_train.shape[1]*x_train.shape[2]))\n",
        "x_test_scaled_reshaped = np.reshape(x_test_scaled, \n",
        "                                     (x_test.shape[0], x_test.shape[1]*x_test.shape[2]))\n",
        "\n",
        "print(x_train_scaled.shape)\n",
        "print(x_test_scaled.shape)\n",
        "print(x_train_scaled_reshaped.shape)\n",
        "print(x_test_scaled_reshaped.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMBihrYTWdah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.applications import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LA2GKi6WxlD",
        "colab_type": "code",
        "outputId": "4bcf7672-4b12-4faf-8de7-857d397b556c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Create base model of VGG19\n",
        "vgg19 = VGG19(weights='imagenet', include_top=False, input_shape = (100, 100, 3), classes = 10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Sn_k41W3Ss",
        "colab_type": "code",
        "outputId": "69f5673f-9fd5-47cf-cc7f-57a918c47409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert the data into 3 channels, as VGG19 requires input of shape (n, n, 3), where n can't be smaller than 48\n",
        "X_train_3_channel = np.dstack([x_train_scaled_reshaped]*3)\n",
        "X_test_3_channel = np.dstack([x_test_scaled_reshaped]*3)\n",
        "\n",
        "print(X_train_3_channel.shape, X_test_3_channel.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784, 3) (10000, 784, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPzGTxdkXQvn",
        "colab_type": "code",
        "outputId": "b8d6474c-2b28-4516-f415-c468565b5aec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert to shape: (n, 28, 28, 3)\n",
        "X_train_3_channel = X_train_3_channel.reshape(-1, 28, 28, 3)\n",
        "X_test_3_channel = X_test_3_channel.reshape(-1, 28, 28, 3)\n",
        "\n",
        "X_train_3_channel.shape, X_test_3_channel.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 3), (10000, 28, 28, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v_M6kpYXUcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e826188-0d07-4bee-fe30-6035645bf876"
      },
      "source": [
        "# Resize the images as (100*100)\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "\n",
        "X_train_3_channel = np.asarray([img_to_array(array_to_img(im, scale=False).resize((100,100))) for im in X_train_3_channel])\n",
        "X_test_3_channel = np.asarray([img_to_array(array_to_img(im, scale=False).resize((100,100))) for im in X_test_3_channel])\n",
        "\n",
        "X_train_3_channel.shape, X_test_3_channel.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 100, 100, 3), (10000, 100, 100, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5RpgH-HXd3B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a6ea5827-3449-49f4-b077-4292eabf70d8"
      },
      "source": [
        "# Split training set into training set(80%) and validation set(20%)\n",
        "X_train_3_ch_sub, X_val_3_ch, y_train_3_ch_sub, y_val_3_ch = train_test_split(X_train_3_channel, \n",
        "                                                                              y_train_cat, \n",
        "                                                                              test_size=0.2, \n",
        "                                                                              random_state=66)\n",
        "\n",
        "print(X_train_3_ch_sub.shape)\n",
        "print(X_val_3_ch.shape)\n",
        "print(X_test_3_channel.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 100, 100, 3)\n",
            "(12000, 100, 100, 3)\n",
            "(10000, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM6bDgOVXvLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the input \n",
        "X_train = preprocess_input(X_train_3_ch_sub)\n",
        "X_val = preprocess_input(X_val_3_ch)\n",
        "X_test = preprocess_input(X_test_3_channel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhhOff58X1zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c4575c88-067f-4e18-8563-8e8eca3b0c07"
      },
      "source": [
        "# Extract features\n",
        "train_features = vgg19.predict(np.array(X_train), batch_size=128, verbose=1)\n",
        "val_features = vgg19.predict(np.array(X_val), batch_size=128, verbose=1)\n",
        "test_features = vgg19.predict(np.array(X_test), batch_size=128, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000/48000 [==============================] - 107s 2ms/step\n",
            "12000/12000 [==============================] - 28s 2ms/step\n",
            "10000/10000 [==============================] - 22s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh8uavc6X8oX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b74656bc-dafe-4ff5-b401-d2e851cb1a1b"
      },
      "source": [
        "print(train_features.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 3, 3, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fusi_hb5X9fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Flatten extracted features\n",
        "train_features = np.reshape(train_features, (48000, 3*3*512))\n",
        "val_features = np.reshape(val_features, (12000, 3*3*512))\n",
        "test_features = np.reshape(test_features, (10000, 3*3*512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlhpYLU1YADw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "\n",
        "# Add densely connected classifier followed by a LeakyReLU layer and final dense layer for the number of classes\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(512, activation='relu', input_dim=(3*3*512)))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyuEmcs7YDLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdyUZP20YFmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit the model with extracted features\n",
        "\n",
        "from keras import callbacks\n",
        "\n",
        "reduce_learning = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    min_delta=0.0001,\n",
        "    cooldown=2,\n",
        "    min_lr=0)\n",
        "\n",
        "eary_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=7,\n",
        "    verbose=1,\n",
        "    mode='auto')\n",
        "\n",
        "callbacks = [reduce_learning, eary_stopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc6WdiSBbnc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6cf53dea-2e7c-4c77-dda4-358bee894d3e"
      },
      "source": [
        "model.fit(train_features,\n",
        "         y_train_3_ch_sub,\n",
        "         batch_size=256,\n",
        "         epochs=100,\n",
        "         verbose=1,\n",
        "         validation_data=(val_features, y_val_3_ch), \n",
        "         callbacks=callbacks)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 4s 81us/step - loss: 3.5753 - acc: 0.1570 - val_loss: 3.5210 - val_acc: 0.2071\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 3s 67us/step - loss: 3.4375 - acc: 0.2039 - val_loss: 3.5100 - val_acc: 0.2008\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 3s 67us/step - loss: 2.6814 - acc: 0.2163 - val_loss: 2.0792 - val_acc: 0.2086\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 3s 68us/step - loss: 2.0747 - acc: 0.2297 - val_loss: 2.0129 - val_acc: 0.2432\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 3s 69us/step - loss: 2.0270 - acc: 0.2428 - val_loss: 1.9989 - val_acc: 0.2765\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 3s 67us/step - loss: 2.0024 - acc: 0.2514 - val_loss: 1.9632 - val_acc: 0.2819\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 3s 67us/step - loss: 1.9751 - acc: 0.2586 - val_loss: 1.9919 - val_acc: 0.2246\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 3s 67us/step - loss: 1.9553 - acc: 0.2665 - val_loss: 2.0514 - val_acc: 0.2612\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.9043 - acc: 0.2950 - val_loss: 1.9001 - val_acc: 0.2967\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8952 - acc: 0.2977 - val_loss: 1.8909 - val_acc: 0.2888\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8857 - acc: 0.3000 - val_loss: 1.8895 - val_acc: 0.2938\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 3s 67us/step - loss: 1.8813 - acc: 0.2992 - val_loss: 1.8853 - val_acc: 0.2761\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 3s 69us/step - loss: 1.8765 - acc: 0.3015 - val_loss: 1.8849 - val_acc: 0.2990\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 3s 68us/step - loss: 1.8759 - acc: 0.3005 - val_loss: 1.8757 - val_acc: 0.3030\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 3s 68us/step - loss: 1.8664 - acc: 0.3061 - val_loss: 1.8657 - val_acc: 0.2878\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8633 - acc: 0.3044 - val_loss: 1.8962 - val_acc: 0.2636\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8565 - acc: 0.3071 - val_loss: 1.8726 - val_acc: 0.3093\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8410 - acc: 0.3206 - val_loss: 1.8461 - val_acc: 0.3256\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8395 - acc: 0.3227 - val_loss: 1.8461 - val_acc: 0.3230\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8385 - acc: 0.3200 - val_loss: 1.8440 - val_acc: 0.3216\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8365 - acc: 0.3244 - val_loss: 1.8469 - val_acc: 0.3133\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8350 - acc: 0.3245 - val_loss: 1.8470 - val_acc: 0.3149\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8315 - acc: 0.3274 - val_loss: 1.8376 - val_acc: 0.3231\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8312 - acc: 0.3294 - val_loss: 1.8382 - val_acc: 0.3348\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8307 - acc: 0.3272 - val_loss: 1.8403 - val_acc: 0.3173\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8302 - acc: 0.3309 - val_loss: 1.8372 - val_acc: 0.3289\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8298 - acc: 0.3299 - val_loss: 1.8371 - val_acc: 0.3314\n",
            "Epoch 28/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8298 - acc: 0.3321 - val_loss: 1.8367 - val_acc: 0.3305\n",
            "Epoch 29/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8297 - acc: 0.3326 - val_loss: 1.8367 - val_acc: 0.3277\n",
            "Epoch 30/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8296 - acc: 0.3301 - val_loss: 1.8371 - val_acc: 0.3340\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 31/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8296 - acc: 0.3352 - val_loss: 1.8366 - val_acc: 0.3310\n",
            "Epoch 32/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8294 - acc: 0.3341 - val_loss: 1.8367 - val_acc: 0.3323\n",
            "Epoch 33/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8294 - acc: 0.3340 - val_loss: 1.8367 - val_acc: 0.3314\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "Epoch 34/100\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 1.8294 - acc: 0.3344 - val_loss: 1.8367 - val_acc: 0.3310\n",
            "Epoch 35/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8294 - acc: 0.3344 - val_loss: 1.8367 - val_acc: 0.3310\n",
            "Epoch 36/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8294 - acc: 0.3345 - val_loss: 1.8367 - val_acc: 0.3310\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "Epoch 37/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8294 - acc: 0.3336 - val_loss: 1.8367 - val_acc: 0.3310\n",
            "Epoch 38/100\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 1.8294 - acc: 0.3337 - val_loss: 1.8367 - val_acc: 0.3310\n",
            "Epoch 00038: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37913c0b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vemSINYlvC1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "a65c1051-853b-4465-f26f-3c69decdf21c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,364,938\n",
            "Trainable params: 2,364,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtb8MxWovEhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}